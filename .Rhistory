daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns
daily_dataset_augmented <- daily_dataset %>%
filter(LCLid != 'LCLid') %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours")
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours")
)
View(weather_daily_darksky)
# Load libraries
library(dplyr)
library(lubridate)
# data sources
daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns, wile filtering for duplicate values
daily_dataset_augmented <- daily_dataset %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
consumption = energy_sum
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours")
)
# Convert weather time column to date
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
icon,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
View(daily_dataset_merged)
# Load libraries
library(dplyr)
library(lubridate)
# data sources
daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns, wile filtering for duplicate values
daily_dataset_augmented <- daily_dataset %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
consumption = energy_sum
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours"),
weather_condition = icon
)
# Convert weather time column to date
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
View(daily_dataset_merged)
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
left_join(informations_households, by = "LCLid") %>%
left_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
weather_daily_darksky[duplicated(weather_daily_darksky), ]
weather_daily_darksky <- weather_daily_darksky[duplicated(weather_daily_darksky), ]
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
weather_daily_darksky <- read.csv(weather_daily_darksky)
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours"),
weather_condition = icon
)
View(weather_daily_darksky)
weather_daily_darksky <- distinct(weather_daily_darksky)
weather_daily_darksky <- distinct(weather_daily_darksky, weather_daily_darksky.day)
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
weather_daily_darksky <- distinct(weather_daily_darksky, weather_daily_darksky.day)
weather_daily_darksky <- distinct(weather_daily_darksky, weather_daily_darksky$day)
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
View(weather_daily_darksky)
# Load libraries
library(dplyr)
library(lubridate)
## STEP 1: IMPORT AND ORGANIZE DATA
# data sources
daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns, wile filtering for duplicate values
daily_dataset_augmented <- daily_dataset %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
consumption = energy_sum
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours"),
weather_condition = icon
)
# Convert weather time column to date
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
weather_daily_darksky <- weather_daily_darksky[distinct(weather_daily_darksky, weather_daily_darksky$day), ]
weather_daily_darksky <- weather_daily_darksky[!duplicated(weather_daily_darksky$day), ]
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
## STEP 2: DATA EXPLORATION, DATA CLEANING AND DATA TRANSFORMATION
ggplot(daily_dataset, aes(x = day)) +
geom_density(fill = "skyblue", color = "darkblue", alpha = 0.8) +
labs(title = "Density Distribution of Daily Dataset",
x = "Day",
y = "Density") +
theme_minimal()
library(ggplot2)
ggplot(daily_dataset, aes(x = day)) +
geom_density(fill = "skyblue", color = "darkblue", alpha = 0.8) +
labs(title = "Density Distribution of Daily Dataset",
x = "Day",
y = "Density") +
theme_minimal()
ggplot(daily_dataset, aes(x = day)) +
geom_density(fill = "skyblue", color = "darkblue", alpha = 0.8) +
labs(title = "Density Distribution of Daily Dataset",
x = "Day",
y = "Density") +
theme_minimal()
freq_table <- table(daily_dataset$day)
freq_data <- as.data.frame(freq_table)
freq_data$day <- as.Date(names(freq_table))
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
geom_point() +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
freq_table <- table(daily_dataset$day)
freq_data <- as.data.frame(freq_table)
freq_data$day <- as.Date(names(freq_table))
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
View(freq_data)
View(daily_dataset_merged)
---
title: "Time Series Analysis and Forecasting Project"
# Load libraries
library(dplyr)
library(lubridate)
library(ggplot2)
# data sources
daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns, wile filtering for duplicate values
daily_dataset_augmented <- daily_dataset %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
consumption = energy_sum
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours"),
weather_condition = icon
)
# Convert weather time column to date
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
weather_daily_darksky <- weather_daily_darksky[!duplicated(weather_daily_darksky$day), ]
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
```
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
library(dplyr)
library(lubridate)
library(ggplot2)
# data sources
daily_dataset <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\daily_dataset.csv"
informations_households <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\informations_households.csv"
uk_bank_holidays <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\uk_bank_holidays.csv"
weather_daily_darksky <- "C:\\Users\\ferol\\Documents\\programming\\TimeSeriesAnalyisis R+ Python\\archive\\weather_daily_darksky.csv"
# import the csv file
daily_dataset <- read.csv(daily_dataset)
informations_households <- read.csv(informations_households)
uk_bank_holidays <- read.csv(uk_bank_holidays)
weather_daily_darksky <- read.csv(weather_daily_darksky)
# flag UK holiday days and add DOW and DOY columns, wile filtering for duplicate values
daily_dataset_augmented <- daily_dataset %>%
mutate(
isUkHoliday = as.numeric(day %in% uk_bank_holidays$Bank.holidays),
day = as.Date(day, format = "%Y-%m-%d"),
dayOfWeek = weekdays(day),
dayOfYear = as.numeric(strftime(day, format = "%j")),
consumption = energy_sum
)
# add sunlight hours column to weather_daily_darksky
weather_daily_darksky <- weather_daily_darksky %>%
mutate(
sunlightHours = difftime(sunsetTime, sunriseTime, units="hours"),
weather_condition = icon
)
# Convert weather time column to date
weather_daily_darksky$day <- as.Date(weather_daily_darksky$time)
weather_daily_darksky <- weather_daily_darksky[!duplicated(weather_daily_darksky$day), ]
# Merge datasets and select only useful columns
daily_dataset_merged <- daily_dataset_augmented %>%
inner_join(informations_households, by = "LCLid") %>%
inner_join(weather_daily_darksky, by = c("day" = "day")) %>%
select(
LCLid,
day,
consumption,
isUkHoliday,
dayOfWeek,
dayOfYear,
stdorToU,
weather_condition,
cloudCover,
windSpeed,
precipType,
uvIndex,
sunlightHours,
temperatureLow,
temperatureMin,
temperatureHigh,
temperatureMax
)
```{r fig.cap = "Daily Dataset density distribution"}
library(ggplot2)
freq_table <- table(daily_dataset$day)
freq_data <- as.data.frame(table(daily_dataset$day))
freq_data$day <- as.Date(names(freq_data))
freq_table <- table(daily_dataset$day)
freq_data <- as.data.frame(table(daily_dataset$day))
freq_data$day <- as.Date(names(freq_table))
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
threshold <- 0.75 * max(freq_data$Freq)
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() + +
geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
threshold <- 0.75 * max(freq_data$Freq)
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
threshold <- 0.74 * max(freq_data$Freq)
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
threshold <- 0.75 * max(freq_data$Freq)
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
daily_dataset_filtered <- daily_dataset[daily_dataset$day %in% freq_data$day[freq_data$Freq >= threshold], ]
daily_dataset_filtered <- daily_dataset_merged[daily_dataset_merged$day %in% freq_data$day[freq_data$Freq >= threshold], ]
unfiltered_data_points = nrow(daily_dataset_merged)
filtered_data_points = nrow(daily_dataset_filtered)
library(ggplot2)
freq_table <- table(daily_dataset$day)
freq_data <- as.data.frame(table(daily_dataset$day))
freq_data$day <- as.Date(names(freq_table))
threshold <- 0.75 * max(freq_data$Freq)
ggplot(freq_data, aes(x = day, y = Freq)) +
geom_line() +
geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
labs(title = "Daily Dataset Frequency Plot", x = "Day", y = "Frequency") +
theme_minimal()
which(is.na(daily_dataset_filtered))
sum(is.na(daily_dataset_filtered))
sum(is.na(daily_dataset_filtered))
summary(daily_dataset_filtered)
View(weather_daily_darksky)
#identifying missing values
sum(is.na(daily_dataset_filtered))
summary(daily_dataset_filtered)
#filtering values whose
daily_dataset_filtered <- daily_dataset_merged[daily_dataset_merged$day %in% freq_data$day[freq_data$Freq >= threshold], ]
unfiltered_data_points_mln = round(nrow(daily_dataset_merged) / 1000000, 1)
filtered_data_points_mln = round(nrow(daily_dataset_filtered) / 1000000, 1)
#identifying missing values
sum(is.na(daily_dataset_filtered))
summary(daily_dataset_filtered)
#identifying missing values
summary(daily_dataset_filtered)
consumption_missing_values = sum(is.na(daily_dataset_filtered$consumption))
windspeed_missing_values = sum(is.na(daily_dataset_filtered$windSpeed))
uvIndex_missing_values = sum(is.na(daily_dataset_filtered$uvIndex))
uvIndex_missing_values = sum(is.na(daily_dataset_filtered$uvIndex))
str(daily_dataset_filtered$uvIndex)
unique(daily_dataset_filtered$uvIndex)
unique(daily_dataset_filtered$windSpeed)
#identifying missing values
summary(daily_dataset_filtered)
consumption_missing_values = sum(is.na(daily_dataset_filtered$consumption))
windspeed_missing_values = sum(is.na(daily_dataset_filtered$windSpeed))
uvIndex_missing_values = sum(is.na(daily_dataset_filtered$uvIndex))
uvIndex_missing_values = is.na(daily_dataset_filtered$uvIndex)
uvIndex_missing_values = which(is.na(daily_dataset_filtered$uvIndex))
uvIndex_missing_values = sum(is.na(daily_dataset_filtered$uvIndex))
#identifying missing values
summary(daily_dataset_filtered)
consumption_missing_values = sum(is.na(daily_dataset_filtered$consumption))
cloudCover_missing_values = sum(is.na(daily_dataset_filtered$cloudCover))
uvIndex_missing_values = sum(is.na(daily_dataset_filtered$uvIndex))
Sys.getenv("RSTUDIO_PANDOC")
file.copy(rmarkdown::pandoc_exec(), "/usr/local/bin/pandoc", overwrite = TRUE)
file.copy(rmarkdown::pandoc_exec(), "C:/Users/ferol/bin/pandoc", overwrite = TRUE)
